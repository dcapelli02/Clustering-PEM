{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec992009",
   "metadata": {},
   "source": [
    "# Prova clustering documenti testuali finale PEM\n",
    "Proviamo a fare un riassunto finale. Vediamo di importare tutti i pacchetti e le funzioni che mi serviranno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6343e214",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import homogeneity_score, completeness_score, v_measure_score, adjusted_rand_score, silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1c73c0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3387 documents - 4 categories\n"
     ]
    }
   ],
   "source": [
    "# Importazione dei dati testuali\n",
    "\n",
    "categories = [\n",
    "    \"alt.atheism\",\n",
    "    \"talk.religion.misc\",\n",
    "    \"comp.graphics\",\n",
    "    \"sci.space\",\n",
    "]\n",
    "\n",
    "dataset = fetch_20newsgroups(\n",
    "    remove=(\"headers\", \"footers\", \"quotes\"),\n",
    "    subset=\"all\",\n",
    "    categories=categories,\n",
    "    shuffle=True,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "labels = dataset.target\n",
    "unique_labels, category_sizes = np.unique(labels, return_counts=True)\n",
    "true_k = unique_labels.shape[0]\n",
    "\n",
    "print(f\"{len(dataset.data)} documents - {true_k} categories\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b6ad3ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_samples: 3387, n_features: 7929\n"
     ]
    }
   ],
   "source": [
    "# Ora creiamo il vettore con le features\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_df=0.5,\n",
    "    min_df=5,\n",
    "    stop_words=\"english\",\n",
    ")\n",
    "#t0 = time()\n",
    "X_tfidf = vectorizer.fit_transform(dataset.data)\n",
    "\n",
    "#print(f\"vectorization done in {time() - t0:.3f} s\")\n",
    "print(f\"n_samples: {X_tfidf.shape[0]}, n_features: {X_tfidf.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae200da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per plottare i dendrogrammi\n",
    "\n",
    "def plot_dendrogram(model, **kwargs):\n",
    "    # Create linkage matrix and then plot the dendrogram\n",
    "\n",
    "    # create the counts of samples under each node\n",
    "    counts = np.zeros(model.children_.shape[0])\n",
    "    n_samples = len(model.labels_)\n",
    "    for i, merge in enumerate(model.children_):\n",
    "        current_count = 0\n",
    "        for child_idx in merge:\n",
    "            if child_idx < n_samples:\n",
    "                current_count += 1  # leaf node\n",
    "            else:\n",
    "                current_count += counts[child_idx - n_samples]\n",
    "        counts[i] = current_count\n",
    "\n",
    "    linkage_matrix = np.column_stack(\n",
    "        [model.children_, model.distances_, counts]\n",
    "    ).astype(float)\n",
    "\n",
    "    # Plot the corresponding dendrogram\n",
    "    dendrogram(linkage_matrix, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07da78c3",
   "metadata": {},
   "source": [
    "### K-Means clustering\n",
    "Dovremmo aver creato tutte le funzioni che ci servivano per il nostro scopo. Proviamo ora a eseguire Kmeans (con 4 cluster) e clustering agglomerativo (sempre con 4 cluster) per poi andare a valutarne le metriche che abbiamo importato. Possiamo ad esempio cercare di usare diverse metriche e dissimilarità per il clustering gerarchico per vedere quale sia il migliore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "120ecc8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of elements assigned to each cluster: [ 516  772 1818  281]\n",
      "True number of documents in each category according to the class labels: [799 973 987 628]\n"
     ]
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters = true_k, max_iter = 100, n_init = 20)\n",
    "\n",
    "model_kmeans = kmeans.fit(X_tfidf)\n",
    "cluster_ids, cluster_sizes = np.unique(model_kmeans.labels_, return_counts=True)\n",
    "print(f\"Number of elements assigned to each cluster: {cluster_sizes}\")\n",
    "\n",
    "print(\n",
    "    \"True number of documents in each category according to the class labels: \"\n",
    "    f\"{category_sizes}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a883bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homogeneity: 0.36088012430609556 \n",
      "Completeness: 0.42492601023855214 \n"
     ]
    }
   ],
   "source": [
    "# Vediamo le varie metriche\n",
    "labels_pred_kmeans = model_kmeans.predict(X_tfidf)\n",
    "hom_kmeans = homogeneity_score(labels, labels_pred_kmeans)\n",
    "comp_kmeans = completeness_score(labels, labels_pred_kmeans)\n",
    "print(f\"Homogeneity: {hom_kmeans} \")\n",
    "print(f\"Completeness: {comp_kmeans} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5027a94e",
   "metadata": {},
   "source": [
    "### Clustering agglomerativo\n",
    "Proviamo ora con il clustering agglomerativo. Usiamo come metrica quella euclidea perchè quella del coseno dà problemi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "970c05ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_clust1 = AgglomerativeClustering(n_clusters=4,\n",
    "                                metric = 'euclidean',\n",
    "                                linkage = 'complete')\n",
    "labels_pred_agg1 = agg_clust1.fit_predict(X_tfidf.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76fdf358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of elements assigned to each cluster: [2977  189  135   86]\n",
      "True number of documents in each category according to the class labels: [799 973 987 628]\n"
     ]
    }
   ],
   "source": [
    "cluster_ids_agg1, cluster_sizes_agg1 = np.unique(labels_pred_agg1, return_counts=True)\n",
    "print(f\"Number of elements assigned to each cluster: {cluster_sizes_agg1}\")\n",
    "\n",
    "print(\n",
    "    \"True number of documents in each category according to the class labels: \"\n",
    "    f\"{category_sizes}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed6d2fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homogeneity: 0.02501046896780025 \n",
      "Completeness: 0.06909987879550528 \n"
     ]
    }
   ],
   "source": [
    "# Vediamo ora le metriche\n",
    "hom_agg1 = homogeneity_score(labels, labels_pred_agg1)\n",
    "comp_agg1 = completeness_score(labels, labels_pred_agg1)\n",
    "print(f\"Homogeneity: {hom_agg1} \")\n",
    "print(f\"Completeness: {comp_agg1} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fd1926",
   "metadata": {},
   "source": [
    "Direi che non risulta molto efficace in questo caso. Proviamo un linkage diverso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9905a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of elements assigned to each cluster: [3384    1    1    1]\n",
      "True number of documents in each category according to the class labels: [799 973 987 628]\n"
     ]
    }
   ],
   "source": [
    "agg_clust2 = AgglomerativeClustering(n_clusters=4,\n",
    "                                metric = 'euclidean',\n",
    "                                linkage = 'single')\n",
    "labels_pred_agg2 = agg_clust2.fit_predict(X_tfidf.toarray())\n",
    "\n",
    "cluster_ids_agg2, cluster_sizes_agg2 = np.unique(labels_pred_agg2, return_counts=True)\n",
    "print(f\"Number of elements assigned to each cluster: {cluster_sizes_agg2}\")\n",
    "\n",
    "print(\n",
    "    \"True number of documents in each category according to the class labels: \"\n",
    "    f\"{category_sizes}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1d8cc94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homogeneity: 0.0008486690602323611 \n",
      "Completeness: 0.14390319976072855 \n"
     ]
    }
   ],
   "source": [
    "# Vediamo ora le metriche\n",
    "hom_agg2 = homogeneity_score(labels, labels_pred_agg2)\n",
    "comp_agg2 = completeness_score(labels, labels_pred_agg2)\n",
    "print(f\"Homogeneity: {hom_agg2} \")\n",
    "print(f\"Completeness: {comp_agg2} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8907173c",
   "metadata": {},
   "source": [
    "Terribile. Proviamo con l'average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70f2976c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of elements assigned to each cluster: [3381    3    2    1]\n",
      "True number of documents in each category according to the class labels: [799 973 987 628]\n"
     ]
    }
   ],
   "source": [
    "agg_clust3 = AgglomerativeClustering(n_clusters=4,\n",
    "                                metric = 'euclidean',\n",
    "                                linkage = 'average')\n",
    "labels_pred_agg3 = agg_clust3.fit_predict(X_tfidf.toarray())\n",
    "\n",
    "cluster_ids_agg3, cluster_sizes_agg3 = np.unique(labels_pred_agg3, return_counts=True)\n",
    "print(f\"Number of elements assigned to each cluster: {cluster_sizes_agg3}\")\n",
    "\n",
    "print(\n",
    "    \"True number of documents in each category according to the class labels: \"\n",
    "    f\"{category_sizes}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d74ef32f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homogeneity: 0.0009849064613946799 \n",
      "Completeness: 0.09131352582073328 \n"
     ]
    }
   ],
   "source": [
    "# Vediamo ora le metriche\n",
    "hom_agg3 = homogeneity_score(labels, labels_pred_agg3)\n",
    "comp_agg3 = completeness_score(labels, labels_pred_agg3)\n",
    "print(f\"Homogeneity: {hom_agg3} \")\n",
    "print(f\"Completeness: {comp_agg3} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33302bee",
   "metadata": {},
   "source": [
    "Proviamo infine la ward (che però non ho spiegato nel documento)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79d3d347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of elements assigned to each cluster: [2100  324   18  945]\n",
      "True number of documents in each category according to the class labels: [799 973 987 628]\n"
     ]
    }
   ],
   "source": [
    "agg_clust4 = AgglomerativeClustering(n_clusters=4,\n",
    "                                metric = 'euclidean',\n",
    "                                linkage = 'ward')\n",
    "labels_pred_agg4 = agg_clust4.fit_predict(X_tfidf.toarray())\n",
    "\n",
    "cluster_ids_agg4, cluster_sizes_agg4 = np.unique(labels_pred_agg4, return_counts=True)\n",
    "print(f\"Number of elements assigned to each cluster: {cluster_sizes_agg4}\")\n",
    "\n",
    "print(\n",
    "    \"True number of documents in each category according to the class labels: \"\n",
    "    f\"{category_sizes}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "424df30f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homogeneity: 0.27864739790528836 \n",
      "Completeness: 0.42212919748123157 \n"
     ]
    }
   ],
   "source": [
    "# Vediamo ora le metriche\n",
    "hom_agg4 = homogeneity_score(labels, labels_pred_agg4)\n",
    "comp_agg4 = completeness_score(labels, labels_pred_agg4)\n",
    "print(f\"Homogeneity: {hom_agg4} \")\n",
    "print(f\"Completeness: {comp_agg4} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbc8d64",
   "metadata": {},
   "source": [
    "Questo non è male tutto sommato. Dovrei provare magari con altre metriche."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52310ce",
   "metadata": {},
   "source": [
    "## Codice dopo incontro del 25.03.24\n",
    "Vediamo di trovare se ci sono effettivamente elementi nulli nella matrice. Le entrate sono tutte non negative: quindi basta che controlliamo la somma. Il codice dopo è poco performante ma almeno dovrebbe restituire un risultato sensato. Ci mette qualche minuto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5891661f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[144, 155, 168, 177, 229, 301, 321, 363, 386, 397, 398, 529, 553, 566, 585, 598, 603, 612, 666, 667, 678, 831, 902, 934, 980, 1010, 1020, 1088, 1112, 1137, 1154, 1158, 1182, 1236, 1298, 1353, 1363, 1426, 1438, 1465, 1485, 1494, 1510, 1554, 1561, 1565, 1574, 1598, 1631, 1718, 1719, 1731, 1767, 1802, 1820, 1870, 1924, 1949, 1982, 1987, 2009, 2025, 2028, 2037, 2094, 2095, 2142, 2160, 2249, 2280, 2284, 2363, 2371, 2380, 2390, 2413, 2414, 2473, 2558, 2564, 2616, 2635, 2750, 2769, 2864, 2938, 2958, 2996, 2998, 3007, 3056, 3059, 3084, 3114, 3184, 3194, 3215, 3224, 3226, 3233, 3241, 3293, 3347, 3360]\n"
     ]
    }
   ],
   "source": [
    "prova = np.zeros(len(X_tfidf.toarray()))\n",
    "zeri = []\n",
    "#caso.append(1)\n",
    "for i in range(len(X_tfidf.toarray())):\n",
    "    a = X_tfidf.toarray()[i].sum()\n",
    "    if (a==0):\n",
    "        zeri.append(i)\n",
    "print(zeri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fa6c83",
   "metadata": {},
   "source": [
    "Copiamo per semplicità la lista degli indici in cui abbiamo solo elementi zero: [144, 155, 168, 177, 229, 301, 321, 363, 386, 397, 398, 529, 553, 566, 585, 598, 603, 612, 666, 667, 678, 831, 902, 934, 980, 1010, 1020, 1088, 1112, 1137, 1154, 1158, 1182, 1236, 1298, 1353, 1363, 1426, 1438, 1465, 1485, 1494, 1510, 1554, 1561, 1565, 1574, 1598, 1631, 1718, 1719, 1731, 1767, 1802, 1820, 1870, 1924, 1949, 1982, 1987, 2009, 2025, 2028, 2037, 2094, 2095, 2142, 2160, 2249, 2280, 2284, 2363, 2371, 2380, 2390, 2413, 2414, 2473, 2558, 2564, 2616, 2635, 2750, 2769, 2864, 2938, 2958, 2996, 2998, 3007, 3056, 3059, 3084, 3114, 3184, 3194, 3215, 3224, 3226, 3233, 3241, 3293, 3347, 3360]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f9be3a02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.data[155]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2fe266",
   "metadata": {},
   "source": [
    "Ce ne sono alcuni che non contengono parole. Potremmo provare semplicemente a rimuoverli. Proviamo una cosa del genere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9a1eef19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3360, 3347, 3293, 3241, 3233, 3226, 3224, 3215, 3194, 3184, 3114, 3084, 3059, 3056, 3007, 2998, 2996, 2958, 2938, 2864, 2769, 2750, 2635, 2616, 2564, 2558, 2473, 2414, 2413, 2390, 2380, 2371, 2363, 2284, 2280, 2249, 2160, 2142, 2095, 2094, 2037, 2028, 2025, 2009, 1987, 1982, 1949, 1924, 1870, 1820, 1802, 1767, 1731, 1719, 1718, 1631, 1598, 1574, 1565, 1561, 1554, 1510, 1494, 1485, 1465, 1438, 1426, 1363, 1353, 1298, 1236, 1182, 1158, 1154, 1137, 1112, 1088, 1020, 1010, 980, 934, 902, 831, 678, 667, 666, 612, 603, 598, 585, 566, 553, 529, 398, 397, 386, 363, 321, 301, 229, 177, 168, 155, 144]\n"
     ]
    }
   ],
   "source": [
    "#caso.pop(0)\n",
    "#dataset.remove\n",
    "print(zeri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "de4d2562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3387\n",
      "3283\n"
     ]
    }
   ],
   "source": [
    "# Proviamo un metodo mio personale\n",
    "\n",
    "dataset_rem = dataset.data\n",
    "print(len(dataset_rem))\n",
    "n_rem = len(zeri)\n",
    "\n",
    "for i in range(n_rem):\n",
    "    dataset_rem.pop(zeri[i] - i)\n",
    "    \n",
    "print(len(dataset_rem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4fc0b40b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_samples: 3283, n_features: 7718\n"
     ]
    }
   ],
   "source": [
    "X1_tfidf = vectorizer.fit_transform(dataset_rem)\n",
    "\n",
    "#print(f\"vectorization done in {time() - t0:.3f} s\")\n",
    "print(f\"n_samples: {X1_tfidf.shape[0]}, n_features: {X1_tfidf.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "18ebbdc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "3283\n"
     ]
    }
   ],
   "source": [
    "X1 = X_tfidf.toarray()\n",
    "print(X1)\n",
    "n_rem = len(zeri)\n",
    "\n",
    "# Creare una nuova matrice senza gli elementi corrispondenti agli indici in caso\n",
    "X1_nuovo = [row for index, row in enumerate(X1) if index not in zeri]\n",
    "\n",
    "print(len(X1_nuovo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a60311e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of elements assigned to each cluster: [3260   19    3    1]\n",
      "True number of documents in each category according to the class labels: [799 973 987 628]\n"
     ]
    }
   ],
   "source": [
    "agg_clust4 = AgglomerativeClustering(n_clusters=4,\n",
    "                                metric = 'cosine',\n",
    "                                linkage = 'average')\n",
    "labels_pred_agg4 = agg_clust4.fit_predict(X1_nuovo)\n",
    "\n",
    "cluster_ids_agg4, cluster_sizes_agg4 = np.unique(labels_pred_agg4, return_counts=True)\n",
    "print(f\"Number of elements assigned to each cluster: {cluster_sizes_agg4}\")\n",
    "\n",
    "print(\n",
    "    \"True number of documents in each category according to the class labels: \"\n",
    "    f\"{category_sizes}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6e43dacc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "prova = np.zeros(len(X1_nuovo))\n",
    "zeri1 = []\n",
    "#caso.append(1)\n",
    "for i in range(len(X1_nuovo)):\n",
    "    a = X1_nuovo[i].sum()\n",
    "    if (a==0):\n",
    "        zeri1.append(i)\n",
    "print(zeri1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cec73c9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.866435068399446"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1_nuovo[144].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f8201b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of elements assigned to each cluster: [3280    1    1    1]\n",
      "True number of documents in each category according to the class labels: [799 973 987 628]\n"
     ]
    }
   ],
   "source": [
    "agg_clust4 = AgglomerativeClustering(n_clusters=4,\n",
    "                                metric = 'cosine',\n",
    "                                linkage = 'single')\n",
    "labels_pred_agg4 = agg_clust4.fit_predict(X1_nuovo)\n",
    "\n",
    "cluster_ids_agg4, cluster_sizes_agg4 = np.unique(labels_pred_agg4, return_counts=True)\n",
    "print(f\"Number of elements assigned to each cluster: {cluster_sizes_agg4}\")\n",
    "\n",
    "print(\n",
    "    \"True number of documents in each category according to the class labels: \"\n",
    "    f\"{category_sizes}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cdc1671d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of elements assigned to each cluster: [3266    4    7    6]\n",
      "True number of documents in each category according to the class labels: [799 973 987 628]\n"
     ]
    }
   ],
   "source": [
    "agg_clust4 = AgglomerativeClustering(n_clusters=4,\n",
    "                                metric = 'cosine',\n",
    "                                linkage = 'complete')\n",
    "labels_pred_agg4 = agg_clust4.fit_predict(X1_nuovo)\n",
    "\n",
    "cluster_ids_agg4, cluster_sizes_agg4 = np.unique(labels_pred_agg4, return_counts=True)\n",
    "print(f\"Number of elements assigned to each cluster: {cluster_sizes_agg4}\")\n",
    "\n",
    "print(\n",
    "    \"True number of documents in each category according to the class labels: \"\n",
    "    f\"{category_sizes}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e9bcbc44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of elements assigned to each cluster: [3278    2    2    1]\n",
      "True number of documents in each category according to the class labels: [799 973 987 628]\n"
     ]
    }
   ],
   "source": [
    "agg_clust4 = AgglomerativeClustering(n_clusters=4,\n",
    "                                metric = 'manhattan',\n",
    "                                linkage = 'average')\n",
    "labels_pred_agg4 = agg_clust4.fit_predict(X1_nuovo)\n",
    "\n",
    "cluster_ids_agg4, cluster_sizes_agg4 = np.unique(labels_pred_agg4, return_counts=True)\n",
    "print(f\"Number of elements assigned to each cluster: {cluster_sizes_agg4}\")\n",
    "\n",
    "print(\n",
    "    \"True number of documents in each category according to the class labels: \"\n",
    "    f\"{category_sizes}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "24099ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of elements assigned to each cluster: [3278    2    2    1]\n",
      "True number of documents in each category according to the class labels: [799 973 987 628]\n"
     ]
    }
   ],
   "source": [
    "agg_clust4 = AgglomerativeClustering(n_clusters=4,\n",
    "                                metric = 'manhattan',\n",
    "                                linkage = 'single')\n",
    "labels_pred_agg4 = agg_clust4.fit_predict(X1_nuovo)\n",
    "\n",
    "cluster_ids_agg4, cluster_sizes_agg4 = np.unique(labels_pred_agg4, return_counts=True)\n",
    "print(f\"Number of elements assigned to each cluster: {cluster_sizes_agg4}\")\n",
    "\n",
    "print(\n",
    "    \"True number of documents in each category according to the class labels: \"\n",
    "    f\"{category_sizes}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a4e0ffc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of elements assigned to each cluster: [3271    3    2    7]\n",
      "True number of documents in each category according to the class labels: [799 973 987 628]\n"
     ]
    }
   ],
   "source": [
    "agg_clust4 = AgglomerativeClustering(n_clusters=4,\n",
    "                                metric = 'manhattan',\n",
    "                                linkage = 'complete')\n",
    "labels_pred_agg4 = agg_clust4.fit_predict(X1_nuovo)\n",
    "\n",
    "cluster_ids_agg4, cluster_sizes_agg4 = np.unique(labels_pred_agg4, return_counts=True)\n",
    "print(f\"Number of elements assigned to each cluster: {cluster_sizes_agg4}\")\n",
    "\n",
    "print(\n",
    "    \"True number of documents in each category according to the class labels: \"\n",
    "    f\"{category_sizes}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bada80f4",
   "metadata": {},
   "source": [
    "Così però non sembrano funzionare molto bene, vanno ancora meglio quelli con la metrica euclidea... Idea: provo a rieseguire quello con metrica euclidea per vedere come risulta la cosa alla fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "128e95f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of elements assigned to each cluster: [2020  340   18  905]\n",
      "True number of documents in each category according to the class labels: [799 973 987 628]\n"
     ]
    }
   ],
   "source": [
    "agg_clust4 = AgglomerativeClustering(n_clusters=4,\n",
    "                                metric = 'euclidean',\n",
    "                                linkage = 'ward')\n",
    "labels_pred_agg4 = agg_clust4.fit_predict(X1_nuovo)\n",
    "\n",
    "cluster_ids_agg4, cluster_sizes_agg4 = np.unique(labels_pred_agg4, return_counts=True)\n",
    "print(f\"Number of elements assigned to each cluster: {cluster_sizes_agg4}\")\n",
    "\n",
    "print(\n",
    "    \"True number of documents in each category according to the class labels: \"\n",
    "    f\"{category_sizes}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d219f7c",
   "metadata": {},
   "source": [
    "Sembra solo aver peggiorato la situazione non ha molto senso... Ricorda che devi modificare il numero di osservazioni nei veri cluster (pensaci più tardi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a88802",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ee658e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
