{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec992009",
   "metadata": {},
   "source": [
    "# Prova clustering documenti testuali finale PEM\n",
    "Proviamo a fare un riassunto finale. Vediamo di importare tutti i pacchetti e le funzioni che mi serviranno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6343e214",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import homogeneity_score, completeness_score, v_measure_score, adjusted_rand_score, silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c73c0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3387 documents - 4 categories\n"
     ]
    }
   ],
   "source": [
    "# Importazione dei dati testuali\n",
    "\n",
    "categories = [\n",
    "    \"alt.atheism\",\n",
    "    \"talk.religion.misc\",\n",
    "    \"comp.graphics\",\n",
    "    \"sci.space\",\n",
    "]\n",
    "\n",
    "dataset = fetch_20newsgroups(\n",
    "    remove=(\"headers\", \"footers\", \"quotes\"),\n",
    "    subset=\"all\",\n",
    "    categories=categories,\n",
    "    shuffle=True,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "labels = dataset.target\n",
    "unique_labels, category_sizes = np.unique(labels, return_counts=True)\n",
    "true_k = unique_labels.shape[0]\n",
    "\n",
    "print(f\"{len(dataset.data)} documents - {true_k} categories\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6ad3ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_samples: 3387, n_features: 7929\n"
     ]
    }
   ],
   "source": [
    "# Ora creiamo il vettore con le features\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_df=0.5,\n",
    "    min_df=5,\n",
    "    stop_words=\"english\",\n",
    ")\n",
    "#t0 = time()\n",
    "X_tfidf = vectorizer.fit_transform(dataset.data)\n",
    "\n",
    "#print(f\"vectorization done in {time() - t0:.3f} s\")\n",
    "print(f\"n_samples: {X_tfidf.shape[0]}, n_features: {X_tfidf.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae200da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per plottare i dendrogrammi\n",
    "\n",
    "def plot_dendrogram(model, **kwargs):\n",
    "    # Create linkage matrix and then plot the dendrogram\n",
    "\n",
    "    # create the counts of samples under each node\n",
    "    counts = np.zeros(model.children_.shape[0])\n",
    "    n_samples = len(model.labels_)\n",
    "    for i, merge in enumerate(model.children_):\n",
    "        current_count = 0\n",
    "        for child_idx in merge:\n",
    "            if child_idx < n_samples:\n",
    "                current_count += 1  # leaf node\n",
    "            else:\n",
    "                current_count += counts[child_idx - n_samples]\n",
    "        counts[i] = current_count\n",
    "\n",
    "    linkage_matrix = np.column_stack(\n",
    "        [model.children_, model.distances_, counts]\n",
    "    ).astype(float)\n",
    "\n",
    "    # Plot the corresponding dendrogram\n",
    "    dendrogram(linkage_matrix, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07da78c3",
   "metadata": {},
   "source": [
    "### K-Means clustering\n",
    "Dovremmo aver creato tutte le funzioni che ci servivano per il nostro scopo. Proviamo ora a eseguire Kmeans (con 4 cluster) e clustering agglomerativo (sempre con 4 cluster) per poi andare a valutarne le metriche che abbiamo importato. Possiamo ad esempio cercare di usare diverse metriche e dissimilarità per il clustering gerarchico per vedere quale sia il migliore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "120ecc8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of elements assigned to each cluster: [ 297  506  754 1830]\n",
      "True number of documents in each category according to the class labels: [799 973 987 628]\n"
     ]
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters = true_k, max_iter = 100, n_init = 20)\n",
    "\n",
    "model_kmeans = kmeans.fit(X_tfidf)\n",
    "cluster_ids, cluster_sizes = np.unique(model_kmeans.labels_, return_counts=True)\n",
    "print(f\"Number of elements assigned to each cluster: {cluster_sizes}\")\n",
    "\n",
    "print(\n",
    "    \"True number of documents in each category according to the class labels: \"\n",
    "    f\"{category_sizes}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a883bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homogeneity: 0.3550608049315449 \n",
      "Completeness: 0.4179607709646504 \n"
     ]
    }
   ],
   "source": [
    "# Vediamo le varie metriche\n",
    "labels_pred_kmeans = model_kmeans.predict(X_tfidf)\n",
    "hom_kmeans = homogeneity_score(labels, labels_pred_kmeans)\n",
    "comp_kmeans = completeness_score(labels, labels_pred_kmeans)\n",
    "print(f\"Homogeneity: {hom_kmeans} \")\n",
    "print(f\"Completeness: {comp_kmeans} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5027a94e",
   "metadata": {},
   "source": [
    "### Clustering agglomerativo\n",
    "Proviamo ora con il clustering agglomerativo. Usiamo come metrica quella euclidea perchè quella del coseno dà problemi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "970c05ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_clust1 = AgglomerativeClustering(n_clusters=4,\n",
    "                                metric = 'euclidean',\n",
    "                                linkage = 'complete')\n",
    "labels_pred_agg1 = agg_clust1.fit_predict(X_tfidf.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76fdf358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of elements assigned to each cluster: [2977  189  135   86]\n",
      "True number of documents in each category according to the class labels: [799 973 987 628]\n"
     ]
    }
   ],
   "source": [
    "cluster_ids_agg1, cluster_sizes_agg1 = np.unique(labels_pred_agg1, return_counts=True)\n",
    "print(f\"Number of elements assigned to each cluster: {cluster_sizes_agg1}\")\n",
    "\n",
    "print(\n",
    "    \"True number of documents in each category according to the class labels: \"\n",
    "    f\"{category_sizes}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed6d2fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homogeneity: 0.02501046896780025 \n",
      "Completeness: 0.06909987879550528 \n"
     ]
    }
   ],
   "source": [
    "# Vediamo ora le metriche\n",
    "hom_agg1 = homogeneity_score(labels, labels_pred_agg1)\n",
    "comp_agg1 = completeness_score(labels, labels_pred_agg1)\n",
    "print(f\"Homogeneity: {hom_agg1} \")\n",
    "print(f\"Completeness: {comp_agg1} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fd1926",
   "metadata": {},
   "source": [
    "Direi che non risulta molto efficace in questo caso. Proviamo un linkage diverso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9905a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of elements assigned to each cluster: [3384    1    1    1]\n",
      "True number of documents in each category according to the class labels: [799 973 987 628]\n"
     ]
    }
   ],
   "source": [
    "agg_clust2 = AgglomerativeClustering(n_clusters=4,\n",
    "                                metric = 'euclidean',\n",
    "                                linkage = 'single')\n",
    "labels_pred_agg2 = agg_clust2.fit_predict(X_tfidf.toarray())\n",
    "\n",
    "cluster_ids_agg2, cluster_sizes_agg2 = np.unique(labels_pred_agg2, return_counts=True)\n",
    "print(f\"Number of elements assigned to each cluster: {cluster_sizes_agg2}\")\n",
    "\n",
    "print(\n",
    "    \"True number of documents in each category according to the class labels: \"\n",
    "    f\"{category_sizes}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1d8cc94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homogeneity: 0.0008486690602323611 \n",
      "Completeness: 0.14390319976072855 \n"
     ]
    }
   ],
   "source": [
    "# Vediamo ora le metriche\n",
    "hom_agg2 = homogeneity_score(labels, labels_pred_agg2)\n",
    "comp_agg2 = completeness_score(labels, labels_pred_agg2)\n",
    "print(f\"Homogeneity: {hom_agg2} \")\n",
    "print(f\"Completeness: {comp_agg2} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8907173c",
   "metadata": {},
   "source": [
    "Terribile. Proviamo con l'average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70f2976c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of elements assigned to each cluster: [3381    3    2    1]\n",
      "True number of documents in each category according to the class labels: [799 973 987 628]\n"
     ]
    }
   ],
   "source": [
    "agg_clust3 = AgglomerativeClustering(n_clusters=4,\n",
    "                                metric = 'euclidean',\n",
    "                                linkage = 'average')\n",
    "labels_pred_agg3 = agg_clust3.fit_predict(X_tfidf.toarray())\n",
    "\n",
    "cluster_ids_agg3, cluster_sizes_agg3 = np.unique(labels_pred_agg3, return_counts=True)\n",
    "print(f\"Number of elements assigned to each cluster: {cluster_sizes_agg3}\")\n",
    "\n",
    "print(\n",
    "    \"True number of documents in each category according to the class labels: \"\n",
    "    f\"{category_sizes}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d74ef32f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homogeneity: 0.0009849064613946799 \n",
      "Completeness: 0.09131352582073328 \n"
     ]
    }
   ],
   "source": [
    "# Vediamo ora le metriche\n",
    "hom_agg3 = homogeneity_score(labels, labels_pred_agg3)\n",
    "comp_agg3 = completeness_score(labels, labels_pred_agg3)\n",
    "print(f\"Homogeneity: {hom_agg3} \")\n",
    "print(f\"Completeness: {comp_agg3} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33302bee",
   "metadata": {},
   "source": [
    "Proviamo infine la ward (che però non ho spiegato nel documento)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79d3d347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of elements assigned to each cluster: [2100  324   18  945]\n",
      "True number of documents in each category according to the class labels: [799 973 987 628]\n"
     ]
    }
   ],
   "source": [
    "agg_clust4 = AgglomerativeClustering(n_clusters=4,\n",
    "                                metric = 'euclidean',\n",
    "                                linkage = 'ward')\n",
    "labels_pred_agg4 = agg_clust4.fit_predict(X_tfidf.toarray())\n",
    "\n",
    "cluster_ids_agg4, cluster_sizes_agg4 = np.unique(labels_pred_agg4, return_counts=True)\n",
    "print(f\"Number of elements assigned to each cluster: {cluster_sizes_agg4}\")\n",
    "\n",
    "print(\n",
    "    \"True number of documents in each category according to the class labels: \"\n",
    "    f\"{category_sizes}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "424df30f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homogeneity: 0.27864739790528836 \n",
      "Completeness: 0.42212919748123157 \n"
     ]
    }
   ],
   "source": [
    "# Vediamo ora le metriche\n",
    "hom_agg4 = homogeneity_score(labels, labels_pred_agg4)\n",
    "comp_agg4 = completeness_score(labels, labels_pred_agg4)\n",
    "print(f\"Homogeneity: {hom_agg4} \")\n",
    "print(f\"Completeness: {comp_agg4} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbc8d64",
   "metadata": {},
   "source": [
    "Questo non è male tutto sommato. Dovrei provare magari con altre metriche."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52310ce",
   "metadata": {},
   "source": [
    "## Codice dopo incontro del 25.03.24\n",
    "Vediamo di trovare se ci sono effettivamente elementi nulli nella matrice. Le entrate sono tutte non negative: quindi basta che controlliamo la somma. Il codice dopo è poco performante ma almeno dovrebbe restituire un risultato sensato. Ci mette qualche minuto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5891661f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[144, 155, 168, 177, 229, 301, 321, 363, 386, 397, 398, 529, 553, 566, 585, 598, 603, 612, 666, 667, 678, 831, 902, 934, 980, 1010, 1020, 1088, 1112, 1137, 1154, 1158, 1182, 1236, 1298, 1353, 1363, 1426, 1438, 1465, 1485, 1494, 1510, 1554, 1561, 1565, 1574, 1598, 1631, 1718, 1719, 1731, 1767, 1802, 1820, 1870, 1924, 1949, 1982, 1987, 2009, 2025, 2028, 2037, 2094, 2095, 2142, 2160, 2249, 2280, 2284, 2363, 2371, 2380, 2390, 2413, 2414, 2473, 2558, 2564, 2616, 2635, 2750, 2769, 2864, 2938, 2958, 2996, 2998, 3007, 3056, 3059, 3084, 3114, 3184, 3194, 3215, 3224, 3226, 3233, 3241, 3293, 3347, 3360]\n"
     ]
    }
   ],
   "source": [
    "prova = np.zeros(len(X_tfidf.toarray()))\n",
    "zeri = []\n",
    "#caso.append(1)\n",
    "for i in range(len(X_tfidf.toarray())):\n",
    "    a = X_tfidf.toarray()[i].sum()\n",
    "    if (a==0):\n",
    "        zeri.append(i)\n",
    "print(zeri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fa6c83",
   "metadata": {},
   "source": [
    "Copiamo per semplicità la lista degli indici in cui abbiamo solo elementi zero: [144, 155, 168, 177, 229, 301, 321, 363, 386, 397, 398, 529, 553, 566, 585, 598, 603, 612, 666, 667, 678, 831, 902, 934, 980, 1010, 1020, 1088, 1112, 1137, 1154, 1158, 1182, 1236, 1298, 1353, 1363, 1426, 1438, 1465, 1485, 1494, 1510, 1554, 1561, 1565, 1574, 1598, 1631, 1718, 1719, 1731, 1767, 1802, 1820, 1870, 1924, 1949, 1982, 1987, 2009, 2025, 2028, 2037, 2094, 2095, 2142, 2160, 2249, 2280, 2284, 2363, 2371, 2380, 2390, 2413, 2414, 2473, 2558, 2564, 2616, 2635, 2750, 2769, 2864, 2938, 2958, 2996, 2998, 3007, 3056, 3059, 3084, 3114, 3184, 3194, 3215, 3224, 3226, 3233, 3241, 3293, 3347, 3360]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f9be3a02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n----------'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.data[177]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2fe266",
   "metadata": {},
   "source": [
    "Ce ne sono alcuni che non contengono parole. Potremmo provare semplicemente a rimuoverli. Proviamo una cosa del genere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9a1eef19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[144, 155, 168, 177, 229, 301, 321, 363, 386, 397, 398, 529, 553, 566, 585, 598, 603, 612, 666, 667, 678, 831, 902, 934, 980, 1010, 1020, 1088, 1112, 1137, 1154, 1158, 1182, 1236, 1298, 1353, 1363, 1426, 1438, 1465, 1485, 1494, 1510, 1554, 1561, 1565, 1574, 1598, 1631, 1718, 1719, 1731, 1767, 1802, 1820, 1870, 1924, 1949, 1982, 1987, 2009, 2025, 2028, 2037, 2094, 2095, 2142, 2160, 2249, 2280, 2284, 2363, 2371, 2380, 2390, 2413, 2414, 2473, 2558, 2564, 2616, 2635, 2750, 2769, 2864, 2938, 2958, 2996, 2998, 3007, 3056, 3059, 3084, 3114, 3184, 3194, 3215, 3224, 3226, 3233, 3241, 3293, 3347, 3360]\n"
     ]
    }
   ],
   "source": [
    "#caso.pop(0)\n",
    "#dataset.remove\n",
    "print(zeri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7229b468",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "3360",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m zeri\u001b[38;5;241m.\u001b[39msort(reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m indice \u001b[38;5;129;01min\u001b[39;00m zeri:\n\u001b[1;32m----> 8\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m dataset1[indice]\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(dataset1)\n",
      "\u001b[1;31mKeyError\u001b[0m: 3360"
     ]
    }
   ],
   "source": [
    "# Proviamo ora a rimuovere gli indici sopra\n",
    "\n",
    "# Ordiniamo il tutto in senso decrescente\n",
    "dataset1 = dataset\n",
    "zeri.sort(reverse=True)\n",
    "\n",
    "for indice in zeri:\n",
    "    del dataset1[indice]\n",
    "    \n",
    "print(dataset1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729f6b87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafe293d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67a161a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c236c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "de4d2562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3387\n",
      "3283\n"
     ]
    }
   ],
   "source": [
    "# Proviamo un metodo mio personale\n",
    "\n",
    "dataset_rem = dataset.data\n",
    "print(len(dataset_rem))\n",
    "n_rem = len(zeri)\n",
    "\n",
    "for i in range(n_rem):\n",
    "    dataset_rem.pop(zeri[i] - i)\n",
    "    \n",
    "print(len(dataset_rem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4fc0b40b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_samples: 3283, n_features: 7718\n"
     ]
    }
   ],
   "source": [
    "X1_tfidf = vectorizer.fit_transform(dataset_rem)\n",
    "\n",
    "#print(f\"vectorization done in {time() - t0:.3f} s\")\n",
    "print(f\"n_samples: {X1_tfidf.shape[0]}, n_features: {X1_tfidf.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0ffbc8e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cosine affinity cannot be used when X contains zero vectors",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [24]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m agg_clust4 \u001b[38;5;241m=\u001b[39m AgglomerativeClustering(n_clusters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m,\n\u001b[0;32m      2\u001b[0m                                 metric \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcosine\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      3\u001b[0m                                 linkage \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maverage\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m labels_pred_agg4 \u001b[38;5;241m=\u001b[39m \u001b[43magg_clust4\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX1_tfidf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m cluster_ids_agg4, cluster_sizes_agg4 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(labels_pred_agg4, return_counts\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of elements assigned to each cluster: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcluster_sizes_agg4\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_agglomerative.py:1124\u001b[0m, in \u001b[0;36mAgglomerativeClustering.fit_predict\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m   1103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_predict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1104\u001b[0m     \u001b[38;5;124;03m\"\"\"Fit and return the result of each sample's clustering assignment.\u001b[39;00m\n\u001b[0;32m   1105\u001b[0m \n\u001b[0;32m   1106\u001b[0m \u001b[38;5;124;03m    In addition to fitting, this method also return the result of the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1122\u001b[0m \u001b[38;5;124;03m        Cluster labels.\u001b[39;00m\n\u001b[0;32m   1123\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py:791\u001b[0m, in \u001b[0;36mClusterMixin.fit_predict\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    773\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    774\u001b[0m \u001b[38;5;124;03mPerform clustering on `X` and returns cluster labels.\u001b[39;00m\n\u001b[0;32m    775\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    787\u001b[0m \u001b[38;5;124;03m    Cluster labels.\u001b[39;00m\n\u001b[0;32m    788\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    789\u001b[0m \u001b[38;5;66;03m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[0;32m    790\u001b[0m \u001b[38;5;66;03m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[1;32m--> 791\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels_\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_agglomerative.py:979\u001b[0m, in \u001b[0;36mAgglomerativeClustering.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    961\u001b[0m \u001b[38;5;124;03m\"\"\"Fit the hierarchical clustering from features, or distance matrix.\u001b[39;00m\n\u001b[0;32m    962\u001b[0m \n\u001b[0;32m    963\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    976\u001b[0m \u001b[38;5;124;03m    Returns the fitted instance.\u001b[39;00m\n\u001b[0;32m    977\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    978\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(X, ensure_min_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m--> 979\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_agglomerative.py:1071\u001b[0m, in \u001b[0;36mAgglomerativeClustering._fit\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1067\u001b[0m distance_threshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistance_threshold\n\u001b[0;32m   1069\u001b[0m return_distance \u001b[38;5;241m=\u001b[39m (distance_threshold \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_distances\n\u001b[1;32m-> 1071\u001b[0m out \u001b[38;5;241m=\u001b[39m memory\u001b[38;5;241m.\u001b[39mcache(tree_builder)(\n\u001b[0;32m   1072\u001b[0m     X,\n\u001b[0;32m   1073\u001b[0m     connectivity\u001b[38;5;241m=\u001b[39mconnectivity,\n\u001b[0;32m   1074\u001b[0m     n_clusters\u001b[38;5;241m=\u001b[39mn_clusters,\n\u001b[0;32m   1075\u001b[0m     return_distance\u001b[38;5;241m=\u001b[39mreturn_distance,\n\u001b[0;32m   1076\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1077\u001b[0m )\n\u001b[0;32m   1078\u001b[0m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_connected_components_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_leaves_, parents) \u001b[38;5;241m=\u001b[39m out[\n\u001b[0;32m   1079\u001b[0m     :\u001b[38;5;241m4\u001b[39m\n\u001b[0;32m   1080\u001b[0m ]\n\u001b[0;32m   1082\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_distance:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\memory.py:353\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_agglomerative.py:693\u001b[0m, in \u001b[0;36m_average_linkage\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    691\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_average_linkage\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    692\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlinkage\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maverage\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 693\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m linkage_tree(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_agglomerative.py:511\u001b[0m, in \u001b[0;36mlinkage_tree\u001b[1;34m(X, connectivity, n_clusters, linkage, affinity, return_distance)\u001b[0m\n\u001b[0;32m    505\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    506\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown linkage option, linkage should be one of \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, but \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m was given\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;241m%\u001b[39m (linkage_choices\u001b[38;5;241m.\u001b[39mkeys(), linkage)\n\u001b[0;32m    508\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m affinity \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcosine\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(\u001b[38;5;241m~\u001b[39mnp\u001b[38;5;241m.\u001b[39many(X, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)):\n\u001b[1;32m--> 511\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCosine affinity cannot be used when X contains zero vectors\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    513\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m connectivity \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    514\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m hierarchy  \u001b[38;5;66;03m# imports PIL\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Cosine affinity cannot be used when X contains zero vectors"
     ]
    }
   ],
   "source": [
    "agg_clust4 = AgglomerativeClustering(n_clusters=4,\n",
    "                                metric = 'cosine',\n",
    "                                linkage = 'average')\n",
    "labels_pred_agg4 = agg_clust4.fit_predict(X1_tfidf.toarray())\n",
    "\n",
    "cluster_ids_agg4, cluster_sizes_agg4 = np.unique(labels_pred_agg4, return_counts=True)\n",
    "print(f\"Number of elements assigned to each cluster: {cluster_sizes_agg4}\")\n",
    "\n",
    "print(\n",
    "    \"True number of documents in each category according to the class labels: \"\n",
    "    f\"{category_sizes}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "60bfb5b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'remove'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [25]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m n_rem \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(zeri)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_rem):\n\u001b[1;32m----> 9\u001b[0m     \u001b[43mX1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mremove\u001b[49m(zeri[i] \u001b[38;5;241m-\u001b[39m i)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'remove'"
     ]
    }
   ],
   "source": [
    "# Proviamo un metodo mio personale\n",
    "\n",
    "X1 = X_tfidf.toarray()\n",
    "print(X1)\n",
    "#print(len(X1))\n",
    "n_rem = len(zeri)\n",
    "\n",
    "for i in range(n_rem):\n",
    "    X1.remove(zeri[i] - i)\n",
    "    \n",
    "#print(len(X1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "435f95ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3387"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "18ebbdc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "3283\n"
     ]
    }
   ],
   "source": [
    "X1 = X_tfidf.toarray()\n",
    "print(X1)\n",
    "n_rem = len(zeri)\n",
    "\n",
    "# Creare una nuova matrice senza gli elementi corrispondenti agli indici in caso\n",
    "X1_nuovo = [row for index, row in enumerate(X1) if index not in zeri]\n",
    "\n",
    "print(len(X1_nuovo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a60311e2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cosine affinity cannot be used when X contains zero vectors",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [29]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m agg_clust4 \u001b[38;5;241m=\u001b[39m AgglomerativeClustering(n_clusters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m,\n\u001b[0;32m      2\u001b[0m                                 metric \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcosine\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      3\u001b[0m                                 linkage \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maverage\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m labels_pred_agg4 \u001b[38;5;241m=\u001b[39m \u001b[43magg_clust4\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m cluster_ids_agg4, cluster_sizes_agg4 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(labels_pred_agg4, return_counts\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of elements assigned to each cluster: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcluster_sizes_agg4\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_agglomerative.py:1124\u001b[0m, in \u001b[0;36mAgglomerativeClustering.fit_predict\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m   1103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_predict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1104\u001b[0m     \u001b[38;5;124;03m\"\"\"Fit and return the result of each sample's clustering assignment.\u001b[39;00m\n\u001b[0;32m   1105\u001b[0m \n\u001b[0;32m   1106\u001b[0m \u001b[38;5;124;03m    In addition to fitting, this method also return the result of the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1122\u001b[0m \u001b[38;5;124;03m        Cluster labels.\u001b[39;00m\n\u001b[0;32m   1123\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py:791\u001b[0m, in \u001b[0;36mClusterMixin.fit_predict\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    773\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    774\u001b[0m \u001b[38;5;124;03mPerform clustering on `X` and returns cluster labels.\u001b[39;00m\n\u001b[0;32m    775\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    787\u001b[0m \u001b[38;5;124;03m    Cluster labels.\u001b[39;00m\n\u001b[0;32m    788\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    789\u001b[0m \u001b[38;5;66;03m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[0;32m    790\u001b[0m \u001b[38;5;66;03m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[1;32m--> 791\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels_\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_agglomerative.py:979\u001b[0m, in \u001b[0;36mAgglomerativeClustering.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    961\u001b[0m \u001b[38;5;124;03m\"\"\"Fit the hierarchical clustering from features, or distance matrix.\u001b[39;00m\n\u001b[0;32m    962\u001b[0m \n\u001b[0;32m    963\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    976\u001b[0m \u001b[38;5;124;03m    Returns the fitted instance.\u001b[39;00m\n\u001b[0;32m    977\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    978\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(X, ensure_min_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m--> 979\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_agglomerative.py:1071\u001b[0m, in \u001b[0;36mAgglomerativeClustering._fit\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1067\u001b[0m distance_threshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistance_threshold\n\u001b[0;32m   1069\u001b[0m return_distance \u001b[38;5;241m=\u001b[39m (distance_threshold \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_distances\n\u001b[1;32m-> 1071\u001b[0m out \u001b[38;5;241m=\u001b[39m memory\u001b[38;5;241m.\u001b[39mcache(tree_builder)(\n\u001b[0;32m   1072\u001b[0m     X,\n\u001b[0;32m   1073\u001b[0m     connectivity\u001b[38;5;241m=\u001b[39mconnectivity,\n\u001b[0;32m   1074\u001b[0m     n_clusters\u001b[38;5;241m=\u001b[39mn_clusters,\n\u001b[0;32m   1075\u001b[0m     return_distance\u001b[38;5;241m=\u001b[39mreturn_distance,\n\u001b[0;32m   1076\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1077\u001b[0m )\n\u001b[0;32m   1078\u001b[0m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_connected_components_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_leaves_, parents) \u001b[38;5;241m=\u001b[39m out[\n\u001b[0;32m   1079\u001b[0m     :\u001b[38;5;241m4\u001b[39m\n\u001b[0;32m   1080\u001b[0m ]\n\u001b[0;32m   1082\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_distance:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\memory.py:353\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_agglomerative.py:693\u001b[0m, in \u001b[0;36m_average_linkage\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    691\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_average_linkage\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    692\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlinkage\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maverage\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 693\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m linkage_tree(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_agglomerative.py:511\u001b[0m, in \u001b[0;36mlinkage_tree\u001b[1;34m(X, connectivity, n_clusters, linkage, affinity, return_distance)\u001b[0m\n\u001b[0;32m    505\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    506\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown linkage option, linkage should be one of \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, but \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m was given\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;241m%\u001b[39m (linkage_choices\u001b[38;5;241m.\u001b[39mkeys(), linkage)\n\u001b[0;32m    508\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m affinity \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcosine\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(\u001b[38;5;241m~\u001b[39mnp\u001b[38;5;241m.\u001b[39many(X, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)):\n\u001b[1;32m--> 511\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCosine affinity cannot be used when X contains zero vectors\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    513\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m connectivity \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    514\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m hierarchy  \u001b[38;5;66;03m# imports PIL\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Cosine affinity cannot be used when X contains zero vectors"
     ]
    }
   ],
   "source": [
    "agg_clust4 = AgglomerativeClustering(n_clusters=4,\n",
    "                                metric = 'cosine',\n",
    "                                linkage = 'average')\n",
    "labels_pred_agg4 = agg_clust4.fit_predict(X1)\n",
    "\n",
    "cluster_ids_agg4, cluster_sizes_agg4 = np.unique(labels_pred_agg4, return_counts=True)\n",
    "print(f\"Number of elements assigned to each cluster: {cluster_sizes_agg4}\")\n",
    "\n",
    "print(\n",
    "    \"True number of documents in each category according to the class labels: \"\n",
    "    f\"{category_sizes}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3035e0ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6e43dacc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "prova = np.zeros(len(X1_nuovo))\n",
    "zeri1 = []\n",
    "#caso.append(1)\n",
    "for i in range(len(X1_nuovo)):\n",
    "    a = X1_nuovo[i].sum()\n",
    "    if (a==0):\n",
    "        zeri1.append(i)\n",
    "print(zeri1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4e9117",
   "metadata": {},
   "source": [
    "Errore: in teoria mi dice che la matrice contiene vettori zero, ma li ho rimossi quindi non capisco perchè non me lo esegua."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec73c9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
